{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca7575d7",
   "metadata": {},
   "source": [
    "# Dallas Restaurants - Web scraping project\n",
    "This project is a web scraping project to get data of the restaurants in dallas using YELP website. Im extracting the following info:\n",
    "- Restaurant name\n",
    "- Rating\n",
    "- Number of Reviews\n",
    "- Price tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6c3e944",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4 as bs\n",
    "import requests\n",
    "\n",
    "import urllib.request as url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be09d898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connet to Amazon\n",
    "\n",
    "URL = \"https://www.amazon.com/Best-Sellers/zgbs/fashion/ref=zg_bs_pg_1?_encoding=UTF8&pg=1\"\n",
    "\n",
    "# Go to https://httpbin.org/get to find your User-Agent and save as headers\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.81 Safari/537.36\", \n",
    "            \"X-Amzn-Trace-Id\": \"Root=1-61739e40-3a3e80222ebb5a2428b857be\", \n",
    "            \"X-Client-Data\": \"CIS2yQEIprbJAQjEtskBCKmdygEIsdHKAQjyg8sBCOryywEI7/LLAQie+csBCN2EzAEI54TMAQi2hcwBCNWFzAEI/4XMAQiBhswBCNSHzAEYqqnKAQ==\"\n",
    "  }\n",
    "\n",
    "page = requests.get(URL, headers = headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce539d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "page_soup = bs.BeautifulSoup(page.text, 'html.parser')\n",
    "page_soup = bs.BeautifulSoup(page_soup.prettify(),'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5983b2de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mains = page_soup.find_all(\"div\", {\"class\": \"a-section a-spacing-none aok-relative\"})\n",
    "len(mains)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f9e691",
   "metadata": {},
   "source": [
    "Main attribute \"div\" with the class seems to occure 50 times as the page shows only 50 results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e101b46",
   "metadata": {},
   "source": [
    "Following *scrap_Amazon* funcition is for scraping the main attributes iteratively for the above info.\n",
    "- First it search for <div tag with class = \"p13n-sc-truncate p13n-sc-line-clamp-2\" to get the parent elements.\n",
    "- Ratings were under <span tag with class = \"a-icon-alt\"  \n",
    "- Prices were under <span tag with class = \"p13n-sc-price\"\n",
    "    - There are price ranges "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2edde13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_Amazon(mains):\n",
    "    for main in mains:\n",
    "        names.append(main.find(\"div\", {\"class\": \"p13n-sc-truncate p13n-sc-line-clamp-2\"}).text.strip())\n",
    "        ratings.append(main.find(\"span\", {\"class\": \"a-icon-alt\"}).text.strip()[0:3])\n",
    "        reviews.append(main.find(\"a\", {\"class\": \"a-size-small a-link-normal\"}).text.strip())\n",
    "        \n",
    "        price = main.find_all(\"span\", {\"class\": \"p13n-sc-price\"})\n",
    "        p1 = price[0].text.strip()\n",
    "        try:\n",
    "            p2 = price[1].text.strip()\n",
    "            prices.append(f\"{p1} - {p2}\")\n",
    "        except:\n",
    "            prices.append(p1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3d7b45",
   "metadata": {},
   "source": [
    "Using above funciton scrap, I'm scraping all the pages with a loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7ca3efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "ratings = []\n",
    "reviews = []\n",
    "prices = []\n",
    "\n",
    "\n",
    "for n in range(1, 3): # there are only 2 pages contaning 50 products each\n",
    "    URL = \"https://www.amazon.com/Best-Sellers/zgbs/fashion/ref=zg_bs_pg_1?_encoding=UTF8&pg=1\"\n",
    "\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.81 Safari/537.36\", \n",
    "                \"X-Amzn-Trace-Id\": \"Root=1-61739e40-3a3e80222ebb5a2428b857be\", \n",
    "                \"X-Client-Data\": \"CIS2yQEIprbJAQjEtskBCKmdygEIsdHKAQjyg8sBCOryywEI7/LLAQie+csBCN2EzAEI54TMAQi2hcwBCNWFzAEI/4XMAQiBhswBCNSHzAEYqqnKAQ==\"\n",
    "              }\n",
    "\n",
    "    page = requests.get(URL, headers = headers)\n",
    "    \n",
    "    page_soup = bs.BeautifulSoup(page.text, 'html.parser')\n",
    "    page_soup = bs.BeautifulSoup(page_soup.prettify(),'html.parser')\n",
    "    \n",
    "    mains = page_soup.find_all(\"div\", {\"class\": \"a-section a-spacing-none aok-relative\"})\n",
    "    scrap_Amazon(mains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c42a93f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n",
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(names))\n",
    "print(len(ratings))\n",
    "print(len(reviews))\n",
    "print(len(prices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34f8a0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a csv file to store the scraped data\n",
    "\n",
    "import csv\n",
    "\n",
    "header = ['Product Name', 'Rating', 'No. reviews', 'Price']\n",
    "\n",
    "with open('Amazon_products.csv', 'w', newline = '', encoding = 'UTF8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(header)\n",
    "    for item in range(len(names)):\n",
    "        writer.writerow([names[item], ratings[item], reviews[item], prices[item]])\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4420667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         Product Name  Rating No. reviews  \\\n",
      "0   LINKIOM Children's Padded Jacket Fashion Print...     1.0           4   \n",
      "1                     Hanes Men's EcoSmart Sweatshirt     4.6     105,443   \n",
      "2   Crocs Unisex-Adult Men's and Women's Classic Clog     4.8     256,878   \n",
      "3   Gildan Men's Fleece Hooded Sweatshirt, Style G...     4.6      67,668   \n",
      "4      Gildan Men's Ultra Cotton T-Shirt, Style G2400     4.6      80,780   \n",
      "..                                                ...     ...         ...   \n",
      "95  Sivvan Women's Comfort Long Sleeve T-Shirt/Und...     4.3      33,837   \n",
      "96  Colorfulkoala Women's Buttery Soft High Waiste...     4.4      34,016   \n",
      "97  Gildan Men's Fleece Zip Hooded Sweatshirt, Sty...     4.7      30,195   \n",
      "98                       Champion Men's Jersey Jogger     4.4      15,971   \n",
      "99   Fruit of the Loom Men's Stay Tucked Crew T-Shirt     4.7      63,019   \n",
      "\n",
      "               Price  \n",
      "0    $18.29 - $32.66  \n",
      "1     $4.99 - $30.70  \n",
      "2   $27.72 - $102.84  \n",
      "3    $11.89 - $37.56  \n",
      "4    $9.99 - $157.68  \n",
      "..               ...  \n",
      "95   $11.19 - $15.99  \n",
      "96            $22.99  \n",
      "97   $13.18 - $40.90  \n",
      "98   $15.00 - $45.81  \n",
      "99  $14.83 - $238.40  \n",
      "\n",
      "[100 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# bring up the csv file\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('Amazon_products.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aae1497",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
